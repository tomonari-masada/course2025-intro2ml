{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNqZL7OwQKY8sxAzEN0tx18",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomonari-masada/course2025-intro2ml/blob/main/08_linear_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWFiqFIHYfMo"
      },
      "source": [
        "# 線形回帰\n",
        "* 線形モデルを使って、数値を予測する問題を解く。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6m9DyPkI2F6c"
      },
      "source": [
        "* scikit-learnの線形回帰を利用\n",
        "  * https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fi9Ak2NAY3qk"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%config InlineBackend.figure_format = 'retina'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqgz8t1qZ2i0"
      },
      "source": [
        "## toy dataで線形回帰の使い方を把握"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JFxIL2CYeSK"
      },
      "source": [
        "fig = plt.figure(figsize=(5, 4))\n",
        "x = [2, 1, -3, -1]\n",
        "y = [-4, -2, 5, 2]\n",
        "plt.plot(x, y, '.')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vz0HEs2KYZXv"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXb12HOgZTDX"
      },
      "source": [
        "reg = LinearRegression()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 次のセルはエラーが出ます。"
      ],
      "metadata": {
        "id": "IoDAPlt1xzUY"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHO7ODHTYtkR"
      },
      "source": [
        "reg.fit(x, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zf5C4CEyZHxF"
      },
      "source": [
        "x = np.array(x)\n",
        "X = x.reshape(-1, 1)\n",
        "print(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2Ti20xbZKM1"
      },
      "source": [
        "reg.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg.coef_"
      ],
      "metadata": {
        "id": "n_qxRnz-11dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg.intercept_"
      ],
      "metadata": {
        "id": "ldzaMK_j14MN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWFMfros1ytc"
      },
      "source": [
        "* x軸上に細かく点を打って各点での予測値をプロット\n",
        "  * 観測データに近い位置に直線が引かれることを確認する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZF-dEu7I1YL_"
      },
      "source": [
        "fig = plt.figure(figsize=(5, 4))\n",
        "xs = np.linspace(-3, 2, 101)\n",
        "ys = reg.predict(xs.reshape(-1, 1))\n",
        "plt.plot(x, y, '.')\n",
        "plt.plot(xs, ys)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(5, 4))\n",
        "xs = np.linspace(-3, 2, 101)\n",
        "# 次の行のように、自力でax + bの値を計算することもできる。\n",
        "ys = reg.coef_ * xs + reg.intercept_\n",
        "plt.plot(x, y, '.')\n",
        "plt.plot(xs, ys)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ubxhgSRc1_Er"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 例題: 住宅価格の予測"
      ],
      "metadata": {
        "id": "ISJ6TW0H6m-g"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ralHCb58ZiAB"
      },
      "source": [
        "\n",
        "### California housing prices\n",
        "* よく例題として使われるデータセット\n",
        "  * https://www.kaggle.com/camnugent/california-housing-prices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPlmmUzmaZCc"
      },
      "source": [
        "### データセットの取得"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5faH25BZPzs"
      },
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "data = fetch_california_housing()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZVvrH_rZmyB"
      },
      "source": [
        "X = data.data\n",
        "y = data.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYt3LblKZtKH"
      },
      "source": [
        "data.feature_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* データの一つの例"
      ],
      "metadata": {
        "id": "-sVZ6KaxREu1"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyQk3WJhZpMH"
      },
      "source": [
        "X[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJtK7x5dacab"
      },
      "source": [
        "### 訓練データ/検証データ/テストデータに分割\n",
        "* 機械学習の計算機実験では、データセットを３つに分割する。\n",
        "  * training data set （訓練データ）\n",
        "  * validation data set （検証データ）\n",
        "  * test data set （テストデータ）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaWvz9V-ZqBA"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* まずテストデータを切り分ける。"
      ],
      "metadata": {
        "id": "G_JPwIrvK8yw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)"
      ],
      "metadata": {
        "id": "logthjCCKTH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 次に検証データを切り分ける。"
      ],
      "metadata": {
        "id": "lhjE0XcBK_s6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=1234)"
      ],
      "metadata": {
        "id": "8UJJN8qEKUCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "Tt42XD7xv2Ye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_val.shape"
      ],
      "metadata": {
        "id": "itHWt6YMRJ9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "id": "wGAtOxRgRKVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"train size {len(X_train)} | validation size {len(X_val)} | test size {len(X_test)}\")"
      ],
      "metadata": {
        "id": "ErshSwgHv6wN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmPYlPauaLq8"
      },
      "source": [
        "### 通常の最小二乗法\n",
        "* 最小二乗法は・・・\n",
        "  * モデルの出力$\\hat{y_i} = a x_i + b$と、実際に観測されている目的変数の値$y_i$との差$\\hat{y_i} - y_i$をとり・・・\n",
        "  * この差を二乗$(\\hat{y_i} - y_i)^2$し・・・\n",
        "  * 全てのデータ点にわたってその2乗の和$\\sum_{i=1}^N (\\hat{y_i} - y_i)^2$をとり・・・\n",
        "  * この和を最小化することで、線形モデルの係数や切片を求める方法。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4n-nrYfZw34"
      },
      "source": [
        "reg = LinearRegression()\n",
        "reg.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg.coef_"
      ],
      "metadata": {
        "id": "0J_Wk0-e2X2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg.intercept_"
      ],
      "metadata": {
        "id": "be_u_vk-2ZEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BENZa3uw3NnG"
      },
      "source": [
        "y_val_predict = reg.predict(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYGmvtGO3RT2"
      },
      "source": [
        "print(y_val_predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plJj0fpc3TB3"
      },
      "source": [
        "print(y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCNn7Cz130T7"
      },
      "source": [
        "* R-squared（決定係数）によって評価する\n",
        "  * 1.0に近いほど良い。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WC1cS3Xi3kEl"
      },
      "source": [
        "print(f'R^2: {reg.score(X_val, y_val)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxhwTVjc39Jn"
      },
      "source": [
        "* 機械学習の世界では、R^2ではなく、直接、予測値の良し悪しを評価する場合がほとんど\n",
        "  * 回帰の場合は真の値と予測値との差の二乗の平均のルート(RMSE; root-mean-square error)を評価によく使う。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwJlq8P13XMB"
      },
      "source": [
        "print(f'RMSE: {np.sqrt(np.mean((y_val - y_val_predict) ** 2))}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1xDVTyi41As"
      },
      "source": [
        "* RMSEは、自分でコードを書かなくても、sklearnに関数が用意されている"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4uBfGbg4UxA"
      },
      "source": [
        "from sklearn.metrics import root_mean_squared_error\n",
        "print(f'RMSE: {root_mean_squared_error(y_val, y_val_predict)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FukHY6l9Ajk"
      },
      "source": [
        "# 線形モデルにおける正則化\n",
        "* 正則化とは、わざとモデルをシンプルなものにすることで・・・\n",
        "* モデルの係数や切片が、訓練データだけにピッタリ合いすぎることを防ぐ手法を言う。\n",
        "  * 訓練データだけにピッタリ合ってしまうと、訓練データ以外のデータで予測がうまくいかなくなる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgvZtDW1aOxw"
      },
      "source": [
        "### リッジ回帰\n",
        "* 最小二乗法だが、同時に、係数の２乗の和が大きくならないようにするモデル\n",
        "  * https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html\n",
        "* パラメータ`alpha`が0のとき、最小二乗法と同じことになる。\n",
        "* パラメータ`alpha`を大きくしていくと、正則化の影響が強くなる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ips-vxdXaQCK"
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "reg = Ridge(alpha=10.0)\n",
        "reg.fit(X_train, y_train)\n",
        "y_val_predict = reg.predict(X_val)\n",
        "print(f'RMSE: {root_mean_squared_error(y_val, y_val_predict)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saDXeXx0aQvy"
      },
      "source": [
        "### Lasso\n",
        "* 最小二乗法だが、同時に、係数の絶対値の和が大きくならないようにするモデル\n",
        "  * https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html\n",
        "* パラメータ`alpha`が0のとき、最小二乗法と同じことになる。\n",
        "* パラメータ`alpha`を大きくしていくと、正則化の影響が強くなる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbAXN0rgaR8L"
      },
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "reg = Lasso(alpha=0.01)\n",
        "reg.fit(X_train, y_train)\n",
        "y_val_predict = reg.predict(X_val)\n",
        "print(f'RMSE: {root_mean_squared_error(y_val, y_val_predict)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDtMCOLN47sg"
      },
      "source": [
        "## テストデータを使った最終的な評価\n",
        "* 通常の最小二乗法、リッジ回帰、Lassoなどで試行錯誤し・・・\n",
        "* 検証データでの評価値が最も良かったモデルについて、最後に一回、テストデータで評価する。\n",
        "* **テストデータの評価値を見て、試行錯誤に戻ってはいけないです。**\n",
        "  * 論文などで報告するのは、テストデータでの評価値。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2FtVX3T5IQK"
      },
      "source": [
        "# もし、Ridge回帰でalpha=100とするのが最も良かったとすると・・・\n",
        "reg = Ridge(alpha=100.0)\n",
        "reg.fit(X_train_val, y_train_val)\n",
        "y_test_predict = reg.predict(X_test)\n",
        "print(f'RMSE: {root_mean_squared_error(y_test, y_test_predict)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 課題20250616\n",
        "* モデルとしてリッジ回帰を使ったとき、検証データについて最小のRMSEを与えるalphaの値を探してください。\n",
        "* モデルとしてLassoを使ったとき、検証データについて最小のRMSEを与えるalphaの値を探してください。\n",
        "* リッジ回帰とLassoとのどちらでRSMEがより小さくなりましたか？\n",
        "* リッジ回帰かLassoか、RMSEがより小さくなった方のalphaの設定を使って、訓練データと検証データを合併したデータで訓練をやり直し、そして、そのモデルでテストデータについて予測をしたときのRMSEを求めてください。"
      ],
      "metadata": {
        "id": "AnDlRz2Gw2Jp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UmcjopyGxuMm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}